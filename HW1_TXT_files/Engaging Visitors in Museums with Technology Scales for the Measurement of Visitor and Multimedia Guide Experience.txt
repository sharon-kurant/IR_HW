Engaging Visitors in Museums with Technology:
Scales for the Measurement of Visitor and Multimedia
Guide Experience
Mohd Kamal Othman, Helen Petrie, and Christopher Power
Human Computer Interaction Research Group,
Department of Computer Science,
University of York,
Heslington East YO10 5GH UK
{kamal,Helen.Petrie,cpower}@cs.york.ac.uk

Abstract. Mobile technologies such as multimedia guides (MMGs) are now an
important part of the visitor experience in museums and other cultural spaces.
We report the development of two scales to measuring visitors’ museum
experiences: the Museum Experience Scale (MES) and the Multimedia Guide
Scale (MGS); these quantitative measures can helpfully complement qualitative
information about visitor experience. A standard psychometric methodology
was used in the development of these scales: from a large set of potentially
relevant statements, 57 were chosen and 255 people rated a museum experience
(102 of whom had used a multimedia guide). A Principal Components analysis
yielded a four factor solution for the MES (Engagement, Knowledge/Learning,
Meaningful Experience and Emotional Connection) and a three factor solution
for the MMGS (General Usability, Learnability and Control, Quality of
Interaction). Comparing respondents who used a MMG during their museum
visit with those who did not, there was a significant difference on the
Engagement component of the MES, with respondents who used a MMG being
significantly more engaged. The other components of the MES did not show
significant differences.
Keywords: Museums, cultural spaces, user experience, multimedia guides,
audio guides.

1 Introduction
Museums and other cultural institutions such as art galleries, historic houses, and
archeological sites, referred to in this paper as cultural spaces, have been using
various technologies to improve their visitors’ experiences for nearly 60 years. The
Stedlijk Museum in Amsterdam was the first museum to use a handheld guide in their
exhibitions in 1952 [1]. It took nearly a decade before other cultural spaces followed
that example, with the American Museum of National History adopting the “Sound
Trek” audio guide in 1961. In addition, a Sony Walkman type system was created for
the famous “Treasures of Tutankhamun” tour in the late 1970’s, whilst the Louvre
museum introduced the first random access guide in 1993.
P. Campos et al. (Eds.): INTERACT 2011, Part IV, LNCS 6949, pp. 92–99, 2011.
© IFIP International Federation for Information Processing 2011

Engaging Visitors in Museums with Technology

93

Emerging technologies such as smart phones and tablet computers are now further
changing the way technologies are used in cultural spaces. In addition, the use of
technology in cultural spaces is now not limited to audio commentary, but may
provide diverse content types such as images, video and multimedia. A recent study
found that 57% of cultural spaces surveyed in North America, Asia and Europe have
adopted multimedia guides [2].
It is important for cultural spaces to embrace new technologies to engage and
stimulate their visitors in exhibitions. The use of these technologies should not be
regarded as replacement of the curated tour or more traditional means to disseminate
information, but instead as further ways to connect and engage visitors with objects,
collections and exhibits. Wasserman argues that the use of mobile technology is more
than an information-distribution platform, and that it should instead connect visitors
with each other, with the institution playing an important role of bringing people
together through shared experiences [3].
Further, Pekarik argues that in order to have diverse and exciting cultural spaces in
the future there must be investigation through rigorous methods on how to increase
the range of satisfying experiences had by visitors [4]. Clearly, technology can play
a major role in helping to create those experiences. However, if technology is not
developed and deployed carefully it is likely that technology could detract from the
visitors’ experience. Therefore, it is important to develop methods and measures for
determining the nature, valence and size of the effects that technology has on visitors’
experiences in cultural spaces.
There are many examples measuring different aspects of user experience that are
useful for studying technology in the cultural spaces domain. The acceptance of
technology by users, a multi-dimensional concept comprised of perceived ease of use
and perceived usefulness of the technology, was originally proposed by Davis and
studied in many different domains [5]. These factors are also discussed in work on
cognitive absorption [6]. There are examples of measuring immersion, the feeling of
being pulled into and becoming lost in the interaction with a piece of technology [7,
8], and qualitative work in examining the engagement of visitors with interactive
exhibits [9]. Finally, there is flow [10], the concept of optimal experience where a
user experiences feelings of satisfaction and achievement when the experience is
complete. This, too, has been examined in many different contexts [11, 12, 13].
However, none of these measures, as defined in previous work, have been developed
specifically for the cultural spaces domain. In this paper, we build on previous work
on user experience to create measurement scales for this domain to quantify the effect
that the use technology has on visitors.
This study was designed to investigate the effects of multimedia guides on the
experiences of visitors to cultural spaces. We will take both a qualitative and
quantitative approach to this question. We are developing standard questionnaires to
measure both visitors’ overall experience, particularly the engagement, with the
exhibition (the Museum Experience Scale, henceforth MES) and the usefulness and
usability of multimedia guides (the Multimedia Guide Scale, henceforth MMGS). We
have presented initial findings on the MES [14] that produced four factor structure,
here we present the final form and the MMGS.
This paper will outline the full development of the two scales, and results of an
initial use of the MES, as well as plans for further development of the research.

94

M.K. Othman, H. Petrie, and C. Power

2 Method
2.1 Scale Development
The development of the two questionnaires followed standard psychometric scale
development [14, 15]. Initially, a large set of topics, ideas and statements were
collected by reviewing relevant previous studies and papers [5, 8, 9, 16, 17, 18, 19]
and materials developed by the UK Council for Museums, Libraries and Archives.
The Generic Learning Outcomes model developed by the MLA [18] was particularly
useful in developing the range of statements. This process resulted in 152 potential
statements for the scales1. Three evaluators then used a consensus process to reduce
the number of statements by grouping them into themes and removing similar or
overlapping statements. This resulted in 57 statements: 37 for the MES and 20 for the
MMGS. The items were presented in the scales as Likert items from 1 meaning
“strongly disagree” to 5 meaning “strongly agree”.
2.2 Procedure
The initial versions of the two scales were presented online using QuestionPro2
survey software. The study was widely publicized via numerous email lists and an
advertisement on Facebook. Publicity asked for people who had visited a museum in
the past six months, with or without a multimedia guide. To encourage participation, a
prize draw for Amazon gift vouchers was offered to all participants.
All participants completed the initial version of the MES and of the MMGS if they
had used a multimedia or audio guide on their museum visit. In addition, they also
completed a short questionnaire to gather information about their museum visit
(which museum, how long the visit lasted, how many people in the party etc), as well
as standard demographic information.
2.3 Participants
255 participants completed the scales. 96 were male, 175 were female. Participants
came from very diverse backgrounds (e.g. country of residence, education or work
background, age). This should help to ensure a robust scale. 102 respondents had used
multimedia guide during their museum visit, 153 participants had not.

3 Results
For each scale, a principal components analysis was performed on the ratings of the
statements to extract the components or groups of questions that elicit similar
responses from participants.

1

The set of potential statements is available at: these are available at
www.cs.york.ac.uk/hci/docs/inital_items.pdf
2
http://www.questionpro.com/

Engaging Visitors in Museums with Technology

95

Table 1. The 4 components of the Museum Experience Scale (MES) and their factor loadings
Engagement
I enjoyed visiting the exhibition

0.69

I felt engaged with the exhibition

0.69

My visit to the exhibition was very
interesting
I felt I was experiencing the
exhibition, rather than just visiting
it
My visit to the exhibition was
inspiring
Meaningful Experience
During my visit I was able to reflect
on the significance of the exhibits
and their meaning
During my visit, I put a lot of effort
into thinking about the exhibition

0.68

Seeing rare exhibits gave me a
sense of wonder about the
exhibition
After visiting the exhibition, I was
still interested to know more about
the topic of the exhibition
Seeing real exhibits of importance
was most satisfying aspect of my
visit to the exhibition

0.50

0.65

0.56

0.74

0.53

0.43

0.43

Knowledge/Learning
The information provided about the
exhibits was clear
I could make sense of most of the
things and saw and did at the
exhibition
I liked graphics associated with the
exhibition
My visit enriched my knowledge
and understanding about specific
exhibits
I discovered new information from
the exhibits
Emotional Connection
The exhibition enabled me to
reminisce about my past

0.64
0.57

0.52
0.52

0.43

0.55

My sense of being in the exhibition
was stronger than my sense of
being in the real world (reversed
relationship)
I was overwhelmed with the
aesthetic/beauty aspect of the
exhibits
I wanted to own exhibits like those
that I saw in the exhibition

0.52

I felt connected with the exhibits

0.45

0.47

0.45

The MES produced four components:
•
•
•
•

Engagement with the exhibitions and exhibits
Knowledge/Learning gained from the exhibition and exhibits
Meaningful
Experiences
from
the
interaction
with
exhibitions/exhibits and/or other visitors
Emotional Connection with the exhibits/exhibitions

the

Factor loadings on the top questions for each component are shown in the Table 1,
below. A factor loading is a measure of how strongly each statement relates to the
overall component (1.0 = perfect relationship to 0.0 = no relationship at all, only
statements with factor loading over 0.43 are listed). From this analysis, a final
selection of 20 questions (5 questions for each component) for the MES was made.
For example, if two of more similar statements were in the same category, the
statement with the higher factor loading was selected.

96

M.K. Othman, H. Petrie, and C. Power

Table 2. The 3 components on the Multimedia Guide Scale (MMGS) and their factor loadings
General Usability
I will use an multimedia guide
0.76
again when I visit an exhibition
(negative correlation)
The multimedia guide was a
0.74
distraction
The information given by the
0.73
multimedia guide was too lengthy
It was difficult to determine
0.68
where I was in the exhibition with
the multimedia guide
The multimedia guide helped me
0.67
to navigate around the exhibition
(negative correlation)
Using the multimedia guide
0.65
enhanced my exhibition visit
(negative correlation)
The multimedia guide was
0.51
complicated to use
It was difficult to select the option 0.51
I wanted with the multimedia
guide
Quality of interaction with the Guide
The multimedia guide clearly 0.72
provided feedback about my
actions
It was clear to me when the 0.54
multimedia guide was taking the
initiative to offer me information
and when I needed to ask it for
information
I became unaware that I was even 0.48
using any controls on the
multimedia guide

Learnability and Control
I felt I was in control of the
multimedia guide
Learning to operate the multimedia
guide was easy
Using the multimedia guide did not
require much training
The controls of the multimedia
guide were difficult to understand
(negative correlation)
The multimedia guide presented
information in an understandable
manner
I found it difficult to read the text
on the screen of the multimedia
guide (negative)

0.78

0.74
0.70
0.64

0.54

0.53

The principal components analysis for the MMGS yielded three components:
•
•
•

General usability of the multimedia guide, for example whether the
functionality of the guide is appropriate, whether it is easy to use
Learnability and control, whether the guide is easy to learn to use, whether
the user felt in control, and whether the information presented in a
meaningful ways
Quality of interaction with the guide, this is often considered part of
usability or user experience, but interestingly in this scale, the aspects
concerning interaction with and feedback from the guide form a separate
component

Engaging Visitors in Museums with Technology

97

Mean Component Score

Table 2 shows the statemen
nts that relate to each component and their factor loadinngs.
The questions that are labellled “negative correlation” mean that high ratings on thhose
questions are associated witth low scores on the scale.
5
4.5
4
3.5
3
2.5
2
1.5
1

MM Guidee
No Guide

Fig. 1. Mean scores on thee four components for multimedia guide and non-guide users

As an initial use of the MES,
M
we compared the experience of participants who had
made their museum visit with
w a multimedia guide with the experience of those w
who
had made their visit witho
out a multimedia guide. There was an overall significcant
difference in scores betweeen two groups of participants (Analysis of variance F 11, 253
= 3.66, p < 0.05). There waas also a significant difference between the four factors ((F =
149.50, df = 3, 759, p < 0.001).
0
There was no interaction between the group and
factor variables.
Figure 1 shows the meean scores on the four MES components for multimeedia
guide and non-guide userss. This shows that scores on all four components w
were
higher (i.e. more positiv
ve) with a guide, although that difference was oonly
significantly higher on thee Engagement component, with multimedia guide ussers
being significantly more en
ngaged than non-guide users (Tukey’s HSD p < 0.05). T
The
lack of significant differen
nce on the other three components is interesting in itsself.
This shows that the use of a multimedia guide has no effect, positive or negativee on
the Knowledge and Learn
ning, Meaningful Experience, or Emotional Connecttion
about an exhibition for musseum visitors.

4 Discussion and Conclusions
This study has developed tw
wo scales for use in the evaluation of visitors’ experiennces
of museums and other cultu
ural spaces. We are not suggesting that these are the oonly
instruments that are needed
d in the evaluation of such visitor experiences, but that tthey

98

M.K. Othman, H. Petrie, and C. Power

can be a useful part of an “evaluation toolkit” available to personnel responsible for
evaluations. Particularly as mobile technologies such as multimedia guides become
an integral part of the museum and cultural space experience, it is important to have
tools available to assist in their evaluation.
The Museum Experience Scale (MES) produced four components: Engagement,
Meaningful Experience, Knowledge/Learning and Emotional Connection. These are
slightly different components from those we found from the initial analysis of data
[14], but the current structure is based on a much larger and more robust sample of
respondents. It is interesting that only the Engagement component produced a
significant difference between multimedia guide users and non-users. Thus use of a
multimedia guide appears to enhance engagement and does not detract from a
meaningful experience of emotional connection with the exhibition.
Clearly the sense and level of engagement with exhibitions and exhibits in
museums varies between visitors. Prior knowledge, motivation, interest, technology,
and time spent in the exhibition may influence engagement. The findings from our
study show that introducing technologies such as multimedia guides are achieving
their aim, to make the museum experience more engaging for visitors. This finding
supports previous research that the use of handheld devices such as multimedia guides
is more appealing to visitors than more conventional and traditional ways of
presenting information [18].
Although this study was a useful contribution in quantifying user experience in
museums with and without multimedia guides, it had several limitations. In
particular, respondents were asked about museum experiences that might be six
months old, which was not ideal. To address this and several other issues, we now
planning a study that will use the two scales in an on-site study of visitor experience
with an archeological exhibition. This will allow us to collect data immediately after
the visitor experience and to concentrate on the experience in one particular museum.
Later research will be able to investigate and compare other types of museum and
cultural spaces and other types of technology. In our next study, we will use two
different forms of multimedia guide to investigate how differences in the presentation
of the guide can affect visitors’ experience of a museum or cultural space. We will
also compare this with other measures of visitor experience such as short interviews.

References
1. Tallon, L.: Introduction: Mobile, Digital and Personal. In: Tallon, L., Walker, K. (eds.)
Digital Technologies and the Museum Experience: Handheld Guides and Other Media.
Altamira Press (2008)
2. Petrie, M., Tallon, L.: The iPhone effect?: Comparing Visitors’ and Museum Professionals
Evolving Expectations Mobile Interpretation Tools. In: Trant, J., Bearman, D. (eds.)
Museums and the Web 2010. Archives and Museums Informatics, Toronto (2010)
3. Wasserman, S.: Beyond Information: Ritual, Relationship and Re-encounter through
Mobile Connectivity. Curator: The Museum Journal 54, 11–24 (2011)
4. Pekarik, A.J.: The Long Horizon: The Shared Value of Museums. Curator: The Museum
Journal 54, 75–78 (2011)
5. Davis, F.D., Bagozzi, R.P., Warshaw, P.R.: User Acceptance of Computer Technology: A
Comparison of Two Theoretical Models. Management Science 35, 982–1003 (1989)

Engaging Visitors in Museums with Technology

99

6. Agarwal, R., Karahana, E.: Time Flies When You’re Having Fun: Cognitive Absorption
and Beliefs about Information Technology Usage. MIS Quarterly 24, 465–694 (2000)
7. Cheng, K., Cairns, P.A.: Behaviour, Realism and Immersion in Games. In: CHI 2005
Extended Abstracts on Human Factors in Computing Systems. ACM Press, Portland
(2005)
8. Haywood, N., Cairns, P.: Engagement with an Interactive Museum Exhibit. In: People and
Computers XIX - The Bigger Picture. Springer, Heidelberg (2005)
9. Jennett, C., Cox, A.L., Cairns, P., Dhoparee, S., Epps, A., Tijs, T., Walton, A.: Measuring
and Defining the Experience of Immersion in Games. International Journal of Human
Computer Studies 66, 641–661 (2008)
10. Csikszentmihalyi, M.: Flow: The Psychology of Optimal Experience. Harper and Row,
New York (1990)
11. Chen, H., Wigand, R.T., Nilan, M.: Optimal Flow Experience in Web Navigation:
Effective Utilization and Management of Emerging Information Technologies. In: Ninth
Information Resources Management Association Conference. Idea Group Publishing, USA
(1998)
12. Rettie, R.: An Exploration of Flow during Internet Use. Internet Research: Electronic
Networking Applications and Policy 11, 103–113 (2001)
13. Gaggioli, A., Bassi, M., Delle Fave, A.: Quality of Experience in Virtual Environments. In:
Riva, G., Davide, F., Ijsselstijn, W.A. (eds.) Being There: Concepts, Effect and
Measurement in User Presence in Synthetic Environments. IOS Press, Amsterdam (2003)
14. Othman, K., Petrie, H., Power, C.: Understanding visitors’ experiences with multimedia
guides in cultural spaces. In: Aljaset, A., et al. (eds.) Proceedings of Transforming Culture
in the Digital Age. University of Tartu, Tartu (2010)
15. Anastasi, A., Urbina, S.: Psychological Testing, 7th edn. Prentice Hall, Upper Saddle River
(1997)
16. DeVellis, R.F.: Scale development: theory and applications, 2nd edn. Sage Publications,
London (2003)
17. Naismith, L., Sharples, M., Ting, J.: Evaluation of CAERUS: A Context Aware Mobile
Guide. In: mLearn 2005, Cape Town (2005)
18. Naismith, L., Smith, P.M.: Using Mobile Technologies for Multimedia Tours in a
Traditional Museum Setting. In: mLearn 2006, Canada (2006)
19. MLA. Inspiring Learning for All, Museum and Libraries Association,
http://www.inspiringlearningforall.gov.uk
20. Pekarik, A.J., Doering, Z., Karns, D.A.: Exploring Satisfying Experiences in Museums.
Curator: The Museum Journal 42, 117–129 (1999)
21. Boehner, K., Gay, G., Larkin, C.: Drawing Evaluation into Design for Mobile Computing:
A Case study of the Renwick’s Gallery’s Hand Held Education Project. International
Journal of Digital Libraries 5, 219–230 (2005)

