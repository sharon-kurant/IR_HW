{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sharonku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re, csv, string, pandas as pd\n",
    "from collections import defaultdict\n",
    "from numpy import loadtxt\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of words in corpus is  536960\n",
      "Dictionary size is  26089\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r\"[a-zA-Z]+\")\n",
    "fdist = FreqDist()\n",
    "\n",
    "dictionary = set()\n",
    "papers = {}\n",
    "path = \"HW1_TXT_files\"\n",
    "stop_words = []\n",
    "all_words = []\n",
    "\n",
    "for file_name in os.listdir(path):\n",
    "    with open(path + os.sep + file_name, 'r', encoding = \"utf8\") as f:\n",
    "        papers[file_name.lower()] = tokenizer.tokenize(f.read())\n",
    "        for word in papers[file_name.lower()]:\n",
    "            fdist[word] += 1\n",
    "            all_words.append(word)\n",
    "        dictionary = dictionary.union(set(papers[file_name.lower()]))\n",
    "\n",
    "amount = sum(fdist.values())\n",
    "print(\"Amount of words in corpus is \", amount)    \n",
    "print(\"Dictionary size is \", len(dictionary))\n",
    "\n",
    "# generate language model\n",
    "for key, value in fdist.items():\n",
    "    fdist[key] = value / amount\n",
    "\n",
    "with open(\"stop_words_english.txt\", \"r\", encoding = \"utf8\") as stop_words_file:\n",
    "    stop_words = stop_words_file.read().split(\"\\n\")\n",
    "\n",
    "dictionary_stopwords = set()\n",
    "dictionary_casefold = set()\n",
    "dictionary_stemming = set()\n",
    "\n",
    "\n",
    "#stop words removal\n",
    "stopwords_filter = [w for w in all_words if not w.lower() in stop_words]\n",
    "dictionary_stopwords = dictionary_stopwords.union(set(stopwords_filter))\n",
    "# generate lang model\n",
    "\n",
    "fdist_stopwords = FreqDist(stopwords_filter)\n",
    "stopwords_amount = sum(fdist_stopwords.values())\n",
    "for key, value in fdist_stopwords.items():\n",
    "    fdist_stopwords[key] = value / stopwords_amount\n",
    "    \n",
    "# case folding\n",
    "casefold = [w.lower() for w in stopwords_filter]\n",
    "dictionary_casefold = dictionary_casefold.union(set(casefold))\n",
    "\n",
    "#generate lang model\n",
    "fdist_casefold = FreqDist(casefold)\n",
    "casefold_amount = sum(fdist_casefold.values())\n",
    "for key, value in fdist_casefold.items():\n",
    "    fdist_casefold[key] = value / casefold_amount\n",
    "\n",
    "# stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemming = [stemmer.stem(w) for w in casefold]\n",
    "dictionary_stemming = dictionary_stemming.union(set(stemming))\n",
    "\n",
    "# generate lang model\n",
    "fdist_stemming = FreqDist(stemming)\n",
    "stemming_amount = sum(fdist_stemming.values())\n",
    "for key, value in fdist_stemming.items():\n",
    "    fdist_stemming[key] = value / stemming_amount\n",
    "\n",
    "for title, paper in papers.items():\n",
    "    stopwords_filter = [w for w in paper if not w.lower() in stop_words]\n",
    "    casefold = [w.lower() for w in stopwords_filter]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemming = [stemmer.stem(w) for w in casefold]\n",
    "    papers[title] = stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial Dictionary size is  26089\n",
      "Dictionary size after stop words removal is  24872\n",
      "Dictionary size after case folding is  20064\n",
      "Dictionary size after stemming is  14363\n"
     ]
    }
   ],
   "source": [
    "print(\"initial Dictionary size is \", len(dictionary))\n",
    "\n",
    "print(\"Dictionary size after stop words removal is \", len(dictionary_stopwords))\n",
    "\n",
    "print(\"Dictionary size after case folding is \", len(dictionary_casefold))\n",
    "\n",
    "print(\"Dictionary size after stemming is \", len(dictionary_stemming))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial language model\n",
      "FreqDist({'the': 0.062270932657926104, 'of': 0.03338609952324195, 'and': 0.028834550059594757, 'to': 0.021897348033373062, 'in': 0.018723927294398094, 'a': 0.017740613825983312, 'is': 0.009320992252681765, 'for': 0.009266984505363528, 'that': 0.009108685935637665, 'The': 0.007769666269368296, ...})\n",
      "\n",
      "language model after stop words removal\n",
      "FreqDist({'museum': 0.010523861221119589, 'mobile': 0.00907506230982125, 'guide': 0.008341106133121301, 'user': 0.008077340632119756, 'visitors': 0.007675958347986973, 'visitor': 0.004690438691723115, 'al': 0.003990886710805976, 'Museum': 0.003922078319240355, 'time': 0.003902964877138794, 'guides': 0.0037194758329638067, ...})\n",
      "\n",
      "language model after case folding\n",
      "FreqDist({'museum': 0.014656187403477117, 'mobile': 0.01151776021040077, 'guide': 0.009690515145491522, 'user': 0.009575834492882154, 'visitors': 0.008417559901527547, 'visitor': 0.005114757106377773, 'guides': 0.004384623618098136, 'context': 0.0042814110307497055, 'al': 0.004021468218168473, 'time': 0.004017645529748161, ...})\n",
      "\n",
      "language model after stemming\n",
      "FreqDist({'museum': 0.01736265080505818, 'guid': 0.014656187403477117, 'visitor': 0.013532317007905319, 'user': 0.013104175904830349, 'mobil': 0.011643908928271074, 'exhibit': 0.009828131928622762, 'visit': 0.005993975443049588, 'applic': 0.005837245217816786, 'interact': 0.005730209942048044, 'studi': 0.004862459670637166, ...})\n"
     ]
    }
   ],
   "source": [
    "print(\"initial language model\")\n",
    "fdist.pprint()\n",
    "\n",
    "print(\"\\nlanguage model after stop words removal\")\n",
    "fdist_stopwords.pprint()\n",
    "\n",
    "print(\"\\nlanguage model after case folding\")\n",
    "fdist_casefold.pprint()\n",
    "\n",
    "print(\"\\nlanguage model after stemming\")\n",
    "fdist_stemming.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdist_initial</th>\n",
       "      <th>fdist_stopwords</th>\n",
       "      <th>fdist_casefold</th>\n",
       "      <th>fdist_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>museum</th>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>0.017363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guid</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitor</th>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.013104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensibility</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shoogle</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitatory</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feasability</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haptics</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37704 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             fdist_initial  fdist_stopwords  fdist_casefold  fdist_stemming\n",
       "museum            0.005127         0.010524        0.014656        0.017363\n",
       "guid                   NaN              NaN             NaN        0.014656\n",
       "visitor           0.002285         0.004690        0.005115        0.013532\n",
       "user              0.003935         0.008077        0.009576        0.013104\n",
       "mobil                  NaN              NaN             NaN        0.011644\n",
       "...                    ...              ...             ...             ...\n",
       "sensibility            NaN              NaN        0.000004             NaN\n",
       "shoogle                NaN              NaN        0.000004             NaN\n",
       "excitatory             NaN              NaN        0.000004             NaN\n",
       "feasability            NaN              NaN        0.000004             NaN\n",
       "haptics                NaN              NaN        0.000004             NaN\n",
       "\n",
       "[37704 rows x 4 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = {\"fdist_initial\": fdist, \"fdist_stopwords\":fdist_stopwords, \"fdist_casefold\":fdist_casefold, \"fdist_stemming\": fdist_stemming}).sort_values(by = \"fdist_stemming\", ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(papers.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26089"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 0.062270932657926104, 'of': 0.03338609952324195, 'and': 0.028834550059594757, 'to': 0.021897348033373062, 'in': 0.018723927294398094, 'a': 0.017740613825983312, 'is': 0.009320992252681765, 'for': 0.009266984505363528, 'that': 0.009108685935637665, 'The': 0.007769666269368296, ...})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012224374255065555"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for initial language model\n",
    "fdist[\"mobile\"]+fdist[\"visitors\"]+fdist[\"guide\"]\n",
    "\n",
    "#for language model after stop words removal\n",
    "\n",
    "# for language model after case folding\n",
    "\n",
    "# for language model after stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'museum': 2753, 'mobile': 2374, 'guide': 2182, 'user': 2113, 'visitors': 2008, 'visitor': 1227, 'al': 1044, 'Museum': 1026, 'time': 1021, 'guides': 973, ...})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(fdist_stopwords.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
